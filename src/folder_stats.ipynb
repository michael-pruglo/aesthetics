{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from downcfg import USHER_CFG\n",
    "\n",
    "MEDIA_DIR = USHER_CFG.dest_dir "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from db_managers import MetadataManager\n",
    "mm = MetadataManager(MEDIA_DIR)\n",
    "mm.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extensions = mm.df.index.str.lower().map(lambda f: f.rsplit('.', maxsplit=1)[1]).value_counts()\n",
    "extensions.plot.bar(title=\"file extensions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm.df.plot(subplots=True, figsize=(14,12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toptags = mm.df['tags'].str.split().explode().value_counts()\n",
    "toptags[:60].plot.bar(figsize=(12,4), title=\"tag frequency\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topawards = mm.df['awards'].str.split().explode().value_counts()\n",
    "topawards[:60].plot.bar(figsize=(12,4), title=\"award frequency\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    with open(\"./tags_vocab.py\", \"w\") as f:\n",
    "        data = \"VOCAB = [\\n\" + ''.join([f'  \"{t}\",\\n' for t in toptags.index]) + \"]\"\n",
    "        f.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm.df.hist(column=['Glicko_pts', 'Glicko_rd', 'ELO_pts', 'stars', 'nmatches'], bins=100, figsize=(20,12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mem_parasytes = []\n",
    "for _, row in mm.df.iterrows():\n",
    "    f = row.name\n",
    "    fullname = os.path.join(MEDIA_DIR, f)\n",
    "    assert os.path.exists(fullname), f\n",
    "    filesize = os.path.getsize(fullname) / 1024**2\n",
    "    ratio = row['stars']/filesize\n",
    "    if ratio<0.1 and row['stars']<2.4:\n",
    "        mem_parasytes.append((filesize, ratio, row['stars'], f))\n",
    "mem_parasytes.sort(reverse=True)\n",
    "totalmb = 0\n",
    "for m, r, s, n in mem_parasytes[:30]:\n",
    "    print(f\"{m:6.1f}mb  {r:8.3f}     {s:4.2f} {n}\")\n",
    "    totalmb += m\n",
    "print(f\"------\\n {totalmb:6.1f}mb\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import start_file\n",
    "from send2trash import send2trash\n",
    "import shutil\n",
    "\n",
    "HANDLE_PARASYTES = 0\n",
    "for *_, fname in mem_parasytes[:HANDLE_PARASYTES]:\n",
    "    fullname = os.path.join(MEDIA_DIR, fname)\n",
    "    assert os.path.exists(fullname), fname\n",
    "    start_file(fullname)    \n",
    "    while True:\n",
    "        usr_action = input(\"what do you want to do? [s,skip/b,buffer/t,todo/r,rm,remove]:\").lower()\n",
    "        if usr_action in [\"s\", \"skip\"]:\n",
    "            break\n",
    "        elif usr_action in [\"b\", \"buffer\"]:\n",
    "            mm.delete(fname)\n",
    "            shutil.move(fullname, USHER_CFG.buffer_dir)\n",
    "            break\n",
    "        elif usr_action in [\"t\", \"todo\"]:\n",
    "            mm.delete(fname)\n",
    "            shutil.move(fullname, os.path.join(USHER_CFG.buffer_dir, \"todo/\"))\n",
    "            break\n",
    "        elif usr_action in [\"r\", \"rm\", \"remove\"]:\n",
    "            mm.delete(fname)\n",
    "            send2trash(fullname)\n",
    "            break\n",
    "        else:\n",
    "            print(\"unknown command\", usr_action, \"try again\")\n",
    "            continue"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Health checks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metadata and file checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "from tags_vocab import VOCAB\n",
    "from metadata import ManualMetadata, get_metadata\n",
    "\n",
    "\n",
    "class TestMeidaItem(unittest.TestCase):\n",
    "    def __init__(self, row):\n",
    "        super().__init__()\n",
    "        self.row = row\n",
    "\n",
    "    def setUp(self):\n",
    "        fullname = os.path.join(MEDIA_DIR, self.row.name)\n",
    "        self.assertTrue(os.path.exists(fullname))\n",
    "        self.disk_meta = get_metadata(fullname)\n",
    "    \n",
    "    def test_row(self):\n",
    "        self.assertFalse(any(self.row.isna()), self.row)\n",
    "        df_meta = ManualMetadata.from_str(self.row['tags'], int(self.row['stars']), self.row['awards'])\n",
    "        self.assertEqual(df_meta, self.disk_meta)\n",
    "    \n",
    "    def test_disk_meta(self):\n",
    "        self.assertTrue(self.disk_meta.tags)\n",
    "        self.assertTrue(self.disk_meta.stars >= 0)\n",
    "        self.assertFalse([t for t in self.disk_meta.tags if t not in VOCAB])\n",
    "        self.assertNotEqual(len([t for t in self.disk_meta.tags if t.startswith(\"known_model\")]), 1, \"unnamed known_model\")\n",
    "        bad_awa = []\n",
    "        for a in self.disk_meta.awards:\n",
    "            if   a.startswith(\"e_\"):   a = a[2:]\n",
    "            elif a.startswith(\"wow_\"): a = a[4:]\n",
    "            else: continue\n",
    "            if a not in VOCAB:                   bad_awa.append((a, \"not in vocab\"))\n",
    "            if a not in self.disk_meta.tags:     bad_awa.append((a, \"not in tags\"))\n",
    "            if any(d in a for d in \"013456789\"): bad_awa.append((a, \"digit\"))\n",
    "        self.assertFalse(bad_awa)\n",
    "    \n",
    "    # Idk how to make it beautiful parametrized :(\n",
    "    def runTest(self):\n",
    "        self.test_row()\n",
    "        self.test_disk_meta()\n",
    "    def shortDescription(self):\n",
    "        return f\"test for {self.row.name}\"\n",
    "\n",
    "\n",
    "suite = unittest.TestSuite(TestMeidaItem(row) for _,row in mm.df[:2000].iterrows())\n",
    "unittest.TextTestRunner().run(suite)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Troublesome filenames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from helpers import better_fname\n",
    "\n",
    "IM_JUST_LOOKING = True\n",
    "\n",
    "\n",
    "def trouble_lvl(s:str) -> int:\n",
    "    FORBIDDEN = re.escape(r'<>:\"/\\|?*,')\n",
    "    EXCELLENT = r'_0-9a-zA-Z\\.'\n",
    "    GOOD = EXCELLENT + r' АБВГДЕЁЖЗИЙКЛМНОПРСТУФХЦЧШЩЪЫЬЭЮЯабвгдеёжзийклмнопрстуфхцчшщъыьэюя\\+\\-'\n",
    "    OKAY = GOOD + r'\\[\\]\\(\\)='\n",
    "    if not s or s.isspace():             return 99\n",
    "    if not s.isprintable():              return 98\n",
    "    if re.search('['+FORBIDDEN+']', s):  return 97\n",
    "    if s.startswith('-'):                return 89\n",
    "    if re.search('[^'+OKAY+']', s):      return 16\n",
    "    if re.search('[^'+GOOD+']', s):      return 15\n",
    "    if re.search('[^'+EXCELLENT+']', s): return 3\n",
    "    if len(s) < 9:                       return 1\n",
    "    return 0\n",
    "\n",
    "troubled_fnames = [(trouble_lvl(f), f) for f in os.listdir(MEDIA_DIR) if os.path.isfile(os.path.join(MEDIA_DIR, f)) and trouble_lvl(f)]\n",
    "print(len(troubled_fnames), \"troubles:\")\n",
    "for lvl, f in sorted(troubled_fnames, reverse=True):\n",
    "    better_f = better_fname(f)\n",
    "    print(lvl, f, \"\\n  \", better_f)\n",
    "    if lvl and f != better_f:\n",
    "        if not IM_JUST_LOOKING: \n",
    "            mm.rename(f, better_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rating systems disagree with overall stars or between themselves:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rating_backends import Glicko, ELO\n",
    "from ae_rater_types import Rating\n",
    "\n",
    "df_consensus = mm.df.copy().reset_index()[['name', 'Glicko_pts', 'Glicko_rd', 'ELO_pts', 'stars']]\n",
    "for cls in Glicko, ELO:\n",
    "    rts = lambda pts: cls().rating_to_stars(Rating(pts))\n",
    "    df_consensus[f'{cls.__name__}_exp_stars'] = df_consensus[f'{cls.__name__}_pts'].map(rts)\n",
    "df_consensus['error_stars'] = (((df_consensus['Glicko_exp_stars'] + df_consensus['ELO_exp_stars']) / 2) - df_consensus['stars']).abs()\n",
    "df_consensus['stars_disagreement'] = (df_consensus['Glicko_exp_stars'] - df_consensus['ELO_exp_stars']).abs()\n",
    "df_consensus = df_consensus[(df_consensus['error_stars']>1e-3) | (df_consensus['stars_disagreement']>1.5)]\n",
    "df_consensus.sort_values(['error_stars', 'stars_disagreement'], ascending=False, inplace=True)\n",
    "print(len(df_consensus), \"disagreements:\")\n",
    "df_consensus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIX_DISAGREEMENTS = 0\n",
    "for _, row in df_consensus[:FIX_DISAGREEMENTS].iterrows():\n",
    "    fullname = os.path.join(MEDIA_DIR, row['name']) \n",
    "    assert os.path.exists(fullname)\n",
    "    start_file(fullname)\n",
    "    usr_stars = float(input(\"how many stars? \"))\n",
    "    assert 0 <= usr_stars <= 7\n",
    "    glicko_rat = Glicko().stars_to_rating(usr_stars)\n",
    "    elo_rat = ELO().stars_to_rating(usr_stars)\n",
    "    upd = {\n",
    "        'stars': usr_stars,\n",
    "        'Glicko_rd': min(int(row['Glicko_rd'])+100, glicko_rat.rd),\n",
    "        'Glicko_pts': glicko_rat.points,\n",
    "        'ELO_pts': elo_rat.points,\n",
    "    }\n",
    "    mm.update(fullname, upd)\n",
    "if FIX_DISAGREEMENTS:\n",
    "    mm._commit()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "f1f939cc381e0fc3af4a8a1b7418d5265e3efb0bbb350b3e606529485a7c6f46"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
