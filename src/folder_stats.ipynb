{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from downcfg import USHER_CFG\n",
    "\n",
    "MEDIA_DIR = USHER_CFG.dest_dir "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbpath = os.path.join(MEDIA_DIR, \"metadata_db.csv\")\n",
    "assert os.path.exists(dbpath)\n",
    "df = pd.read_csv(dbpath, keep_default_na=False).sort_values('stars', ascending=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extensions = df['name'].str.lower().str.rsplit('.', n=1, expand=True)[1].value_counts()\n",
    "extensions.plot.bar(title=\"file extensions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(subplots=True, figsize=(14,12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toptags = df['tags'].str.split().explode().value_counts()\n",
    "toptags[:60].plot.bar(figsize=(12,4), title=\"tag frequency\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topawards = df['awards'].str.split().explode().value_counts()\n",
    "topawards[:60].plot.bar(figsize=(12,4), title=\"award frequency\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    with open(\"./tags_vocab.py\", \"w\") as f:\n",
    "        data = \"VOCAB = [\\n\" + ''.join([f'  \"{t}\",\\n' for t in toptags.index]) + \"]\"\n",
    "        f.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hist(column=['Glicko_pts', 'Glicko_rd', 'ELO_pts', 'stars', 'nmatches'], bins=100, figsize=(20,12))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Health checks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metadata and file checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "from tags_vocab import VOCAB\n",
    "from metadata import ManualMetadata, get_metadata\n",
    "\n",
    "\n",
    "class TestMeidaItem(unittest.TestCase):\n",
    "    def __init__(self, row):\n",
    "        super().__init__()\n",
    "        self.row = row\n",
    "\n",
    "    def setUp(self):\n",
    "        fullname = os.path.join(MEDIA_DIR, self.row['name'])\n",
    "        self.assertTrue(os.path.exists(fullname))\n",
    "        self.disk_meta = get_metadata(fullname)\n",
    "    \n",
    "    def test_row(self):\n",
    "        self.assertFalse(any(self.row.isna()), self.row)\n",
    "        df_meta = ManualMetadata.from_str(self.row['tags'], int(self.row['stars']), self.row['awards'])\n",
    "        self.assertEqual(df_meta, self.disk_meta)\n",
    "    \n",
    "    def test_disk_meta(self):\n",
    "        self.assertTrue(self.disk_meta.tags)\n",
    "        self.assertTrue(self.disk_meta.stars >= 0)\n",
    "        self.assertFalse([t for t in self.disk_meta.tags if t not in VOCAB])\n",
    "        self.assertFalse([a for a in self.disk_meta.awards if a.startswith(\"e_\") and a[2:] not in VOCAB])\n",
    "    \n",
    "    # Idk how to make it beautiful parametrized :(\n",
    "    def runTest(self):\n",
    "        self.test_row()\n",
    "        self.test_disk_meta()\n",
    "    def shortDescription(self):\n",
    "        return f\"test for file {self.row['name']}\"\n",
    "\n",
    "\n",
    "suite = unittest.TestSuite(TestMeidaItem(row) for _,row in df[:301].iterrows())\n",
    "unittest.TextTestRunner().run(suite)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Troublesome filenames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import random\n",
    "\n",
    "def trouble_lvl(s:str) -> int:\n",
    "    FORBIDDEN = re.escape(r'<>:\"/\\|?*,')\n",
    "    EXCELLENT = r'_0-9a-zA-Z\\.'\n",
    "    GOOD = EXCELLENT + r' АБВГДЕЁЖЗИЙКЛМНОПРСТУФХЦЧШЩЪЫЬЭЮЯабвгдеёжзийклмнопрстуфхцчшщъыьэюя\\+\\-'\n",
    "    OKAY = GOOD + r'\\[\\]\\(\\)='\n",
    "    if not s or s.isspace():             return 99\n",
    "    if not s.isprintable():              return 98\n",
    "    if re.search('['+FORBIDDEN+']', s):  return 97\n",
    "    if s.startswith('-'):                return 89\n",
    "    if re.search('[^'+OKAY+']', s):      return 16\n",
    "    if re.search('[^'+GOOD+']', s):      return 15\n",
    "    if re.search('[^'+EXCELLENT+']', s): return 3\n",
    "    if len(s) < 10:                      return 1\n",
    "    return 0\n",
    "\n",
    "def better_fname(fname:str) -> str:\n",
    "    class Table:\n",
    "        rus = {'а':'a', 'б':'b', 'в':'v', 'г':'g', 'д':'d', 'е':'e', 'ё':'e', 'ж':'zh', 'з':'z', 'и':'i', 'й':'j', 'к':'k', 'л':'l', 'м':'m', 'н':'n', 'о':'o', 'п':'p', 'р':'r', 'с':'s', 'т':'t', 'у':'u', 'ф':'f', 'х':'h', 'ц':'c', 'ч':'ch', 'ш':'sh', 'щ':'sh', 'ъ':'_', 'ы':'i', 'ь':'_', 'э':'e', 'ю':'ju', 'я':'ya'}\n",
    "        def __getitem__(self, i):\n",
    "            c = chr(i)\n",
    "            if not re.search(r'[^_0-9a-zA-Z]', c): return c\n",
    "            if c in \" -,+[]()\": return '_'\n",
    "            if c in self.rus: return self.rus[c]\n",
    "            if c.lower() in self.rus: return self.rus[c.lower()].upper()\n",
    "            return str(random.randint(10,99))\n",
    "\n",
    "    root, ext = os.path.splitext(fname)\n",
    "    root = root.translate(Table())\n",
    "    if len(root) < 5:\n",
    "        root += str(random.randint(100000,999999))\n",
    "    return root + ext\n",
    "\n",
    "def show_troubled_fnames():\n",
    "    troubles = [(trouble_lvl(f), f) for f in os.listdir(MEDIA_DIR) if os.path.isfile(os.path.join(MEDIA_DIR, f))]\n",
    "    for lvl, f in sorted(troubles, reverse=True):\n",
    "        print(lvl, f, \"\\n  \", better_fname(f))\n",
    "\n",
    "def fix_troubled_fnames(n):\n",
    "    for _,row in df.iterrows():\n",
    "        if n<1: break\n",
    "        f = row['name']\n",
    "        better_f = better_fname(f)\n",
    "        if input(f\"do you wanna rename {f} to {better_f}? \") in \"Yy\":\n",
    "            n -= 1\n",
    "            # row['name'] = better_f ????\n",
    "            # os.rename(os.path.join(MEDIA_DIR, f), os.path.join(MEDIA_DIR, better_f))\n",
    "    # df.to_csv(os.path.join(MEDIA_DIR, \"metadata_db_fixed.csv\"))\n",
    "\n",
    "show_troubled_fnames()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rating systems disagree too much:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rating_backends import Glicko, ELO\n",
    "from ae_rater_types import Rating\n",
    "\n",
    "TOO_MUCH_DISAGREEMENT = 0.9\n",
    "\n",
    "df_consensus = df.copy()[['name', 'Glicko_pts', 'Glicko_rd', 'ELO_pts', 'stars']]\n",
    "for cls in Glicko, ELO:\n",
    "    rts = lambda pts: cls().rating_to_stars(Rating(pts))\n",
    "    df_consensus[f'{cls.__name__}_exp_stars'] = df_consensus[f'{cls.__name__}_pts'].map(rts)\n",
    "df_consensus['stars_disagreement'] = (df_consensus['Glicko_exp_stars'] - df_consensus['ELO_exp_stars']).abs()\n",
    "df_consensus = df_consensus[df_consensus['stars_disagreement']>TOO_MUCH_DISAGREEMENT]\n",
    "df_consensus.sort_values('stars_disagreement', ascending=False, inplace=True, ignore_index=True)\n",
    "df_consensus['stars_disagreement'].plot()\n",
    "df_consensus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "f1f939cc381e0fc3af4a8a1b7418d5265e3efb0bbb350b3e606529485a7c6f46"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
