{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from downcfg import USHER_CFG\n",
    "\n",
    "MEDIA_DIR = USHER_CFG.dest_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from db_managers import MetadataManager\n",
    "mm = MetadataManager(MEDIA_DIR)\n",
    "mm.df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extensions = mm.df.index.str.lower().map(lambda f: f.rsplit('.', maxsplit=1)[1]).value_counts()\n",
    "extensions.plot.bar(title=\"file extensions\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm.df.plot(subplots=True, figsize=(14,12), xticks=range(0,len(mm.df),1000))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toptags = mm.df['tags'].str.split().explode().value_counts()\n",
    "toptags[:60].plot.bar(figsize=(12,4), title=\"tag frequency\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topawards = mm.df['awards'].str.split().explode().value_counts()\n",
    "topawards[:60].plot.bar(figsize=(12,4), title=\"award frequency\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    with open(\"./tags_vocab.py\", \"w\") as f:\n",
    "        data = \"VOCAB = [\\n\" + ''.join([f'  \"{t}\",\\n' for t in toptags.index]) + \"]\\n\\n\"\n",
    "        specawards = [a for a in topawards.index if not a.startswith((\"e_\", \"wow_\"))]\n",
    "        data += \"SPECIAL_AWARDS = [\\n\" + ''.join([f'  \"{a}\",\\n' for a in specawards]) + \"]\\n\"\n",
    "        f.write(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm.df.hist(column=['Glicko_pts', 'Glicko_rd', 'ELO_pts', 'stars', 'nmatches'], bins=100, figsize=(20,12))\n",
    "for star in range(7,0,-1):\n",
    "    print(f\"{star}+\", len(mm.df[mm.df['stars']>=star]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_awa_count = pd.concat([mm.df[col].str.split().str.len() for col in ['tags', 'awards']], axis=1)\n",
    "tag_awa_count.reset_index().plot(legend=True, figsize=(16,6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tags_vocab import VOCAB\n",
    "tags_df = pd.DataFrame({tag:mm.df['tags'].str.contains(tag,regex=False).astype(int)+\n",
    "                            mm.df['awards'].str.contains(\"e_\"+tag,regex=False)+\n",
    "                            mm.df['awards'].str.contains(\"wow_\"+tag,regex=False)\n",
    "                        for tag in VOCAB})\n",
    "tags_df['tagsum'] = tags_df.sum(axis=1)\n",
    "tags_df = pd.concat([mm.df, tags_df], axis=1)\n",
    "tags_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for method in ['pearson', 'kendall', 'spearman']:\n",
    "    correlations = tags_df.corrwith(tags_df['stars'], method=method).where(lambda c: abs(c)>0.2).dropna()\n",
    "    correlations.sort_values(ascending=False, inplace=True)\n",
    "    correlations.plot.bar(title=method)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mem_parasytes = []\n",
    "for _, row in mm.df.iterrows():\n",
    "    f = row.name\n",
    "    fullname = os.path.join(MEDIA_DIR, f)\n",
    "    assert os.path.exists(fullname), f\n",
    "    filesize = os.path.getsize(fullname) / 1024**2\n",
    "    ratio = row['stars']/filesize\n",
    "    if ratio<0.1 and row['stars']<2.4:\n",
    "        mem_parasytes.append((filesize, ratio, row['stars'], f))\n",
    "mem_parasytes.sort(reverse=True)\n",
    "totalmb = 0\n",
    "for m, r, s, n in mem_parasytes[:30]:\n",
    "    print(f\"{m:6.1f}mb  {r:8.3f}     {s:4.2f} {n}\")\n",
    "    totalmb += m\n",
    "print(f\"------\\n {totalmb:6.1f}mb\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import start_file\n",
    "from send2trash import send2trash\n",
    "import shutil\n",
    "\n",
    "HANDLE_PARASYTES = 0\n",
    "for *_, fname in mem_parasytes[:HANDLE_PARASYTES]:\n",
    "    fullname = os.path.join(MEDIA_DIR, fname)\n",
    "    assert os.path.exists(fullname), fname\n",
    "    start_file(fullname)\n",
    "    while True:\n",
    "        usr_action = input(\"what do you want to do? [s,skip/b,buffer/t,todo/r,rm,remove]:\").lower()\n",
    "        if usr_action in [\"s\", \"skip\"]:\n",
    "            break\n",
    "        elif usr_action in [\"b\", \"buffer\"]:\n",
    "            mm.delete(fname)\n",
    "            shutil.move(fullname, USHER_CFG.buffer_dir)\n",
    "            break\n",
    "        elif usr_action in [\"t\", \"todo\"]:\n",
    "            mm.delete(fname)\n",
    "            shutil.move(fullname, os.path.join(USHER_CFG.buffer_dir, \"todo/\"))\n",
    "            break\n",
    "        elif usr_action in [\"r\", \"rm\", \"remove\"]:\n",
    "            mm.delete(fname)\n",
    "            send2trash(fullname)\n",
    "            break\n",
    "        else:\n",
    "            print(\"unknown command\", usr_action, \"try again\")\n",
    "            continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BACKUP_VIP = True\n",
    "VIP_THRESHOLD = 5.0\n",
    "BACKUP_DIR = None\n",
    "\n",
    "vips = None\n",
    "if BACKUP_VIP and os.path.exists(BACKUP_DIR):\n",
    "    vips = mm.df[mm.df['stars']>=VIP_THRESHOLD]\n",
    "    for _, row in vips.iterrows():\n",
    "        fullname = os.path.join(MEDIA_DIR, row[\"name\"])\n",
    "        dest = os.path.join(BACKUP_DIR, row[\"name\"])\n",
    "        print(f\"copying {fullname} to {dest}...\")\n",
    "        # copy\n",
    "    # copy csv\n",
    "vips\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Health checks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metadata and file checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ignored_files = [f for f in os.listdir(MEDIA_DIR)\n",
    "                 if os.path.isfile(os.path.join(MEDIA_DIR, f))\n",
    "                 and not f.endswith(\".csv\")\n",
    "                 and f not in mm.df.index]\n",
    "if ignored_files:\n",
    "    print(len(ignored_files), \"ignored files:\", ignored_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "from tags_vocab import VOCAB\n",
    "from metadata import ManualMetadata, get_metadata\n",
    "\n",
    "\n",
    "class TestMeidaItem(unittest.TestCase):\n",
    "    def __init__(self, row):\n",
    "        super().__init__()\n",
    "        self.row = row\n",
    "\n",
    "    def setUp(self):\n",
    "        fullname = os.path.join(MEDIA_DIR, self.row.name)\n",
    "        self.assertTrue(os.path.exists(fullname))\n",
    "        self.disk_meta = get_metadata(fullname)\n",
    "\n",
    "    def test_row(self):\n",
    "        self.assertFalse(any(self.row.isna()), self.row)\n",
    "        df_meta = ManualMetadata.from_str(self.row['tags'], int(self.row['stars']), self.row['awards'])\n",
    "        self.assertEqual(df_meta, self.disk_meta)\n",
    "\n",
    "    def test_disk_meta(self):\n",
    "        self.assertFalse(self.disk_meta.get_errors())\n",
    "        if (warn := self.disk_meta.get_warnings()):\n",
    "            print(f\"warning {self.row.name} {warn}\")\n",
    "\n",
    "    # Idk how to make it beautiful parametrized :(\n",
    "    def runTest(self):\n",
    "        self.test_row()\n",
    "        self.test_disk_meta()\n",
    "    def shortDescription(self):\n",
    "        return f\"test for {self.row.name}\"\n",
    "\n",
    "\n",
    "suite = unittest.TestSuite(TestMeidaItem(row) for _,row in mm.df[:990].iterrows())\n",
    "unittest.TextTestRunner().run(suite)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Troublesome filenames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from helpers import better_fname\n",
    "\n",
    "IM_JUST_LOOKING = True\n",
    "\n",
    "\n",
    "def trouble_lvl(s:str) -> int:\n",
    "    FORBIDDEN = re.escape(r'<>:\"/\\|?*,')\n",
    "    EXCELLENT = r'_0-9a-zA-Z\\.'\n",
    "    GOOD = EXCELLENT + r' АБВГДЕЁЖЗИЙКЛМНОПРСТУФХЦЧШЩЪЫЬЭЮЯабвгдеёжзийклмнопрстуфхцчшщъыьэюя\\+\\-'\n",
    "    OKAY = GOOD + r'\\[\\]\\(\\)='\n",
    "    if not s or s.isspace():             return 99\n",
    "    if not s.isprintable():              return 98\n",
    "    if re.search('['+FORBIDDEN+']', s):  return 97\n",
    "    if s.startswith('-'):                return 89\n",
    "    if re.search('[^'+OKAY+']', s):      return 16\n",
    "    if re.search('[^'+GOOD+']', s):      return 15\n",
    "    if re.search('[^'+EXCELLENT+']', s): return 3\n",
    "    if len(s) < 9:                       return 1\n",
    "    return 0\n",
    "\n",
    "troubled_fnames = [(trouble_lvl(f), f) for f in os.listdir(MEDIA_DIR) if os.path.isfile(os.path.join(MEDIA_DIR, f)) and trouble_lvl(f)]\n",
    "print(len(troubled_fnames), \"troubles:\")\n",
    "for lvl, f in sorted(troubled_fnames, reverse=True):\n",
    "    better_f = better_fname(f)\n",
    "    print(lvl, f, \"\\n  \", better_f)\n",
    "    if lvl and f != better_f:\n",
    "        if not IM_JUST_LOOKING:\n",
    "            mm.rename(f, better_f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rating systems disagree with overall stars or between themselves:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rating_backends import Glicko, ELO\n",
    "from ae_rater_types import Rating\n",
    "\n",
    "df_consensus = mm.df.copy().reset_index()[['name', 'Glicko_pts', 'Glicko_rd', 'ELO_pts', 'stars']]\n",
    "for cls in Glicko, ELO:\n",
    "    rts = lambda pts: cls().rating_to_stars(Rating(pts))\n",
    "    df_consensus[f'{cls.__name__}_exp_stars'] = df_consensus[f'{cls.__name__}_pts'].map(rts)\n",
    "df_consensus['error_stars'] = (((df_consensus['Glicko_exp_stars'] + df_consensus['ELO_exp_stars']) / 2) - df_consensus['stars']).abs()\n",
    "df_consensus['stars_disagreement'] = (df_consensus['Glicko_exp_stars'] - df_consensus['ELO_exp_stars']).abs()\n",
    "df_consensus = df_consensus[(df_consensus['error_stars']>1e-3) | (df_consensus['stars_disagreement']>1.5)]\n",
    "df_consensus.sort_values(['error_stars', 'stars_disagreement'], ascending=False, inplace=True)\n",
    "print(len(df_consensus), \"disagreements:\")\n",
    "df_consensus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIX_DISAGREEMENTS = 0\n",
    "for _, row in df_consensus[:FIX_DISAGREEMENTS].iterrows():\n",
    "    fullname = os.path.join(MEDIA_DIR, row['name'])\n",
    "    assert os.path.exists(fullname)\n",
    "    start_file(fullname)\n",
    "    usr_stars = float(input(\"how many stars? \"))\n",
    "    # usr_stars = float(row['stars'])\n",
    "    assert 0 <= usr_stars <= 7\n",
    "    glicko_rat = Glicko().stars_to_rating(usr_stars)\n",
    "    elo_rat = ELO().stars_to_rating(usr_stars)\n",
    "    upd = {\n",
    "        'stars': usr_stars,\n",
    "        'Glicko_rd': min(int(row['Glicko_rd'])+100, glicko_rat.rd),\n",
    "        'Glicko_pts': glicko_rat.points,\n",
    "        'ELO_pts': elo_rat.points,\n",
    "    }\n",
    "    mm.update(fullname, upd)\n",
    "if FIX_DISAGREEMENTS:\n",
    "    mm._commit()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "f1f939cc381e0fc3af4a8a1b7418d5265e3efb0bbb350b3e606529485a7c6f46"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
